{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d5907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import randint\n",
    "import kaggle\n",
    "\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd961bac",
   "metadata": {},
   "source": [
    "# seraching from web \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a9a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your search term (e.g., medical equipment sales): electronics sales\n",
      "Datasets found:\n",
      "1. edusanketdk/electronics - Amazon Electronics Products Sales\n",
      "2. bhanupratapbiswas/superstore-sales - Superstore Sales üõíüè∑Ô∏èüõçÔ∏èüì¶üè™\n",
      "3. bhavikjikadara/global-electronics-retailers - Global Electronics Retailers\n",
      "4. tarkkaanko/amazon - amazon reviews for sentiment analysis\n",
      "5. fekihmea/sales-store-overview - Sales Store overview\n",
      "6. Download a custom dataset \n"
     ]
    }
   ],
   "source": [
    "def generate_custom_data(num_rows):\n",
    "    data = {\n",
    "        \"DATE\": pd.date_range(start='1/1/2021', periods=num_rows, freq='D'),\n",
    "        \"ITEM CODE\": [f'{randint(100000, 999999)}' for _ in range(num_rows)],  # 6-digit item codes\n",
    "        \"actual sales\": [randint(1, 100) for _ in range(num_rows)]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "    \n",
    "\n",
    "def search_and_download_datasets():\n",
    "    search_term = input(\"Enter your search term (e.g., medical equipment sales): \")\n",
    "    \n",
    "    # Searching for datasets on Kaggle\n",
    "    search_result = kaggle.api.dataset_list(search=search_term)\n",
    "    \n",
    "    if search_result:\n",
    "        print(\"Datasets found:\")\n",
    "        i=0\n",
    "        j=0\n",
    "        for i, dataset in enumerate(search_result[:5]):  # Display first 5 datasets found\n",
    "            print(f\"{i+1}. {dataset.ref} - {dataset.title}\")\n",
    "            i=i+1\n",
    "        \n",
    "        j=i+1\n",
    "        print(f\"{j}. Download a custom dataset \")\n",
    "            \n",
    "        choice=input(\"Which dataset you want to download(enter the number)\")\n",
    "        choice =int(choice)\n",
    "        \n",
    "        if choice == j:\n",
    "            fake_df= generate_custom_data(100)\n",
    "            fake_df.to_csv('C:/Users/proshan/OneDrive - SymphonyAI RETAIL CPG/Desktop/Projects/csv dataset generator/Downloads/dataset.csv', index=False)     \n",
    "            print(\"Custom dataset saved\")\n",
    "        else:\n",
    "\n",
    "            dataset_to_download = search_result[choice-1].ref  \n",
    "            kaggle.api.dataset_download_files(dataset_to_download, path='Downloads', unzip=True)\n",
    "            print(f\"Downloaded {dataset_to_download}\")\n",
    "#             # Example: Download the first dataset found (be mindful of the dataset size and terms)\n",
    "    else:\n",
    "        print(\"No datasets found. Try refining your search term.\")\n",
    "        print(\"Generaing a custom dataset\")\n",
    "        fake_df2= generate_custom_data(100)\n",
    "        fake_df2.to_csv('C:/Users/proshan/OneDrive - SymphonyAI RETAIL CPG/Desktop/Projects/csv dataset generator/Downloads/dataset.csv', index=False)     \n",
    "        print(\"dataset saved\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_and_download_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399c19a",
   "metadata": {},
   "source": [
    "# handling multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd  # Make sure to import pandas\n",
    "\n",
    "# Define a placeholder for the generate_custom_data function if it's not defined\n",
    "# You should replace this with your actual function definition\n",
    "def generate_custom_data(n):\n",
    "    print(f\"Generating a custom dataset with {n} entries.\")\n",
    "\n",
    "downloads_folder = 'C:/Users/proshan/OneDrive - SymphonyAI RETAIL CPG/Desktop/Projects/csv dataset generator/Downloads'\n",
    "output_file_path = os.path.join(downloads_folder, \"output.csv\")  # It's good to specify the complete path including the file name for clarity\n",
    "\n",
    "files = glob.glob(os.path.join(downloads_folder, '*'))\n",
    "files = [f for f in files if os.path.isfile(f)]\n",
    "\n",
    "if len(files) == 0:\n",
    "    print(\"The folder is empty.\")\n",
    "    generate_custom_data(100)\n",
    "elif len(files) == 1:\n",
    "    print(\"There is a single file in the folder.\")\n",
    "else:\n",
    "    print(f\"There are {len(files)} files in the folder.\")\n",
    "    all_files = glob.glob(os.path.join(downloads_folder, \"*.csv\"))\n",
    "\n",
    "    li = []\n",
    "\n",
    "    try:\n",
    "        for filename in all_files:\n",
    "            df = pd.read_csv(filename, index_col=None, header=0, sep=';')\n",
    "            li.append(df)\n",
    "\n",
    "        frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "        # Assuming you want to save the concatenated DataFrame to a file\n",
    "        frame.to_csv(output_file_path, index=False, sep=';')\n",
    "        print(f\"All files have been concatenated into {output_file_path}.\")\n",
    "    except Exception as e:\n",
    "        print(\"There are multiple datasets which cannot be concatenated into one due to the following error:\", e)\n",
    "        print(\"Generating custom dataset.\")\n",
    "        generate_custom_data(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9f0de",
   "metadata": {},
   "source": [
    "# renaming to test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Path to the Downloads directory where the file to rename is located\n",
    "# downloads_path = 'C:/Users/proshan/OneDrive - SymphonyAI RETAIL CPG/Desktop/Projects/csv dataset generator/Downloads'\n",
    "\n",
    "# # List all files in the Downloads directory\n",
    "# downloaded_files = os.listdir(downloads_path)\n",
    "\n",
    "# # Assuming there is only one file in the directory or you're only interested in the first .csv file\n",
    "# for file in downloaded_files:\n",
    "#     if file.endswith('.csv'):\n",
    "#         original_file_path = os.path.join(downloads_path, file)\n",
    "#         new_file_name = 'test.csv'\n",
    "#         new_file_path = os.path.join(downloads_path, new_file_name)\n",
    "#         try:\n",
    "#             # Rename the file\n",
    "#             os.rename(original_file_path, new_file_path)\n",
    "#             print(f\"File {file} has been renamed to {new_file_name}\")\n",
    "#             break  # If the renaming is done, exit the loop\n",
    "#         except FileNotFoundError:\n",
    "#             print(f\"The file {original_file_path} does not exist.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred: {e}\")\n",
    "#         break  # Exit the loop after trying to rename the first .csv file found\n",
    "# else:\n",
    "#     # If no .csv files were found in the loop\n",
    "#     print(\"No .csv files found in the directory.\")\n",
    "\n",
    "import os\n",
    "\n",
    "# Path to the Downloads directory where the files to rename are located\n",
    "downloads_path = 'C:/Users/proshan/OneDrive - SymphonyAI RETAIL CPG/Desktop/Projects/csv dataset generator/Downloads'\n",
    "\n",
    "# List all files in the Downloads directory\n",
    "downloaded_files = os.listdir(downloads_path)\n",
    "\n",
    "# New file names we want to use if they're not already taken\n",
    "new_csv_file_name = 'test.csv'\n",
    "new_excel_file_name = 'test.xlsx'\n",
    "\n",
    "# Paths to the new files\n",
    "new_csv_file_path = os.path.join(downloads_path, new_csv_file_name)\n",
    "new_excel_file_path = os.path.join(downloads_path, new_excel_file_name)\n",
    "\n",
    "# Check if 'test.csv' already exists\n",
    "if os.path.exists(new_csv_file_path):\n",
    "    print(f\"A file named {new_csv_file_name} already exists.\")\n",
    "else:\n",
    "    # Rename the first .csv file found\n",
    "    for file in downloaded_files:\n",
    "        if file.endswith('.csv'):\n",
    "            original_file_path = os.path.join(downloads_path, file)\n",
    "            try:\n",
    "                os.rename(original_file_path, new_csv_file_path)\n",
    "                print(f\"File {file} has been renamed to {new_csv_file_name}\")\n",
    "                break\n",
    "            except FileNotFoundError:\n",
    "                print(f\"The file {original_file_path} does not exist.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "# Now check if 'test.xlsx' already exists\n",
    "if os.path.exists(new_excel_file_path):\n",
    "    print(f\"A file named {new_excel_file_name} already exists.\")\n",
    "else:\n",
    "    # Rename the first .xls or .xlsx file found\n",
    "    for file in downloaded_files:\n",
    "        if file.endswith('.xls') or file.endswith('.xlsx'):\n",
    "            original_file_path = os.path.join(downloads_path, file)\n",
    "            try:\n",
    "                os.rename(original_file_path, new_excel_file_path)\n",
    "                print(f\"File {file} has been renamed to {new_excel_file_name}\")\n",
    "                break\n",
    "            except FileNotFoundError:\n",
    "                print(f\"The file {original_file_path} does not exist.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba110862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'C:/Users/proshan/OneDrive - SymphonyAI RETAIL CPG/Desktop/Projects/csv dataset generator/Downloads'\n",
    "\n",
    "# Get the list of files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Check each file's extension and read it accordingly\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    if file.endswith('.csv'):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(file_path, encoding='latin1')\n",
    "        # Do something with the CSV file\n",
    "    elif file.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "        # Do something with the Excel file\n",
    "    else:\n",
    "        print(f\"Unsupported file format: {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6cccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633faf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sales' in df.columns and 'price' in df.columns:\n",
    "    df=df.drop('price',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a6237",
   "metadata": {},
   "source": [
    "# nlp tokkenisation to find the column called sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Ensure you have the necessary nltk datasets downloaded\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c88c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "import re\n",
    "\n",
    "def find_synonyms(words):\n",
    "    synonyms = set()\n",
    "    for word in words:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonyms.add(lemma.name().replace('_', ' '))\n",
    "    return synonyms\n",
    "\n",
    "# Find synonyms of \"sale\" and \"price\"\n",
    "words_to_find_synonyms_for = [\"sale\", \"price\"]\n",
    "combined_synonyms = find_synonyms(words_to_find_synonyms_for)\n",
    "\n",
    "# Adding 'sales' in case it's not included through wordnet\n",
    "combined_synonyms.add('sales')\n",
    "\n",
    "# Function to check if a column name is related to \"sale\" or \"price\"\n",
    "def is_related(column_name):\n",
    "    # Define patterns to exclude specific column names like 'retail_price'\n",
    "    excluded_patterns = [\n",
    "        '^retail.*',  # Starts with 'retail'\n",
    "        '^wholesale.*',  # Starts with 'wholesale'\n",
    "        '.*_price$',  # Ends with '_price'\n",
    "        # Add more patterns as necessary\n",
    "    ]\n",
    "\n",
    "    # Convert column name to lowercase and replace underscores with spaces\n",
    "    column_name = column_name.lower().replace('_', ' ')\n",
    "\n",
    "    # Check for excluded patterns\n",
    "    for pattern in excluded_patterns:\n",
    "        if re.match(pattern, column_name):\n",
    "            return False\n",
    "\n",
    "    # Check if the column name contains 'amount' or any synonym of \"sale\" or \"price\"\n",
    "    if \"amount\" == column_name or any(synonym == column_name for synonym in combined_synonyms):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "columns_to_rename = {}\n",
    "for col in df.columns:\n",
    "    if is_related(col):\n",
    "        columns_to_rename[col] = 'actual sales'\n",
    "\n",
    "# Rename columns using the dictionary to handle potential multiple matches\n",
    "df.rename(columns=columns_to_rename, inplace=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d66bd4",
   "metadata": {},
   "source": [
    "# currency conversion to INR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'actual sales' in df.columns:\n",
    "    \n",
    "    first_value = str(df['actual sales'].iloc[0])\n",
    "    if first_value.startswith('$'):\n",
    "        exchange_rate = 75  # Define the exchange rate from USD to INR\n",
    "\n",
    "        def dollars_to_rupees(value):\n",
    "            # This function checks if a value is a dollar amount and converts it to rupees.\n",
    "            if isinstance(value, str) and value.startswith('$'):\n",
    "                # Remove the dollar sign and commas, then convert to float\n",
    "                numeric_value = float(value.replace('$', '').replace(',', ''))\n",
    "                # Convert the dollar amount to rupees\n",
    "                return numeric_value * exchange_rate\n",
    "            elif isinstance(value, str):\n",
    "                # If value is a string but not in dollars, just remove commas\n",
    "                value_no_commas = value.replace(',', '') \n",
    "                return float(value_no_commas)\n",
    "            else:\n",
    "                # If value is already a number, return it as is.\n",
    "                return value\n",
    "\n",
    "        # Apply the function to the 'actual sales' column for conversion\n",
    "        df['actual sales'] = df['actual sales'].apply(dollars_to_rupees)\n",
    "\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_custom_data(num_rows):\n",
    "    data = {\n",
    "        \"DATE\": pd.date_range(start='1/1/2021', periods=num_rows, freq='D'),\n",
    "        \"ITEM CODE\": [f'{randint(100000, 999999)}' for _ in range(num_rows)],  # 6-digit item codes\n",
    "        \"actual sales\": [randint(1, 100) for _ in range(num_rows)]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "if 'actual sales' not in df.columns:\n",
    "    # Column not found, so we generate a new dataframe\n",
    "    df = generate_custom_data(100)\n",
    "    \n",
    "    # Remove the original test.csv file\n",
    "#     file_path = 'C:/Users/proshan/OneDrive - SymphonyAI RETAIL CPG/Desktop/Projects/csv dataset generator/Downloads/test.csv'\n",
    "#     os.remove(file_path)\n",
    "    \n",
    "#     # Save the newly generated dataframe as test.csv in the same location\n",
    "#     df.to_csv(file_path, index=False)  # index=False to avoid saving the index column\n",
    "    \n",
    "#     print(\"Original file removed and new data saved as test.csv.\")\n",
    "# else:\n",
    "#     print(\"Column 'actual sales' exists in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_custom_data(num_rows):\n",
    "    data = {\n",
    "        \"DATE\": pd.date_range(start='1/1/2021', periods=num_rows, freq='D'),\n",
    "        \"ITEM CODE\": [f'{randint(100000, 999999)}' for _ in range(num_rows)],  # 6-digit item codes\n",
    "        \"actual sales\": [randint(1, 100) for _ in range(num_rows)]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "actual_sales_cols = [col for col in df.columns if col == 'actual sales']\n",
    "if len(actual_sales_cols) > 1:\n",
    "    # Check which 'actual sales' columns have numeric data types\n",
    "    numeric_cols = [col for col in actual_sales_cols if pd.api.types.is_numeric_dtype(df[col])]\n",
    "    \n",
    "    if len(numeric_cols) == 0:\n",
    "        print(\"No numeric 'actual sales' columns to keep.\")\n",
    "    else:\n",
    "        # If there are non-numeric 'actual sales' columns, drop them\n",
    "        if len(numeric_cols) < len(actual_sales_cols):\n",
    "            non_numeric_cols = list(set(actual_sales_cols) - set(numeric_cols))\n",
    "            df = df.drop(columns=non_numeric_cols)\n",
    "            print(f\"Dropped non-numeric 'actual sales' columns: {non_numeric_cols}\")\n",
    "        \n",
    "        # If all 'actual sales' columns are numeric or after dropping non-numeric ones\n",
    "        # Keep only the first 'actual sales' column and drop the rest\n",
    "        df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "        print(\"Kept only one 'actual sales' column and dropped any duplicates.\")\n",
    "if len(actual_sales_cols)==1:\n",
    "    non_numeric_mask = pd.to_numeric(df['actual sales'], errors='coerce').isnull()\n",
    "\n",
    "    if non_numeric_mask.any():\n",
    "        print(\"There are non-numeric values in the 'actual sales' column.\")\n",
    "        # Call generate_dataset() function\n",
    "        df=generate_custom_data(100)\n",
    "\n",
    "# The modified DataFrame is now in df with only one 'actual sales' column\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2620dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a420c53",
   "metadata": {},
   "source": [
    "# generating forecasted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sample DataFrame with a column 'actual sales' for demonst\n",
    "# df = pd.DataFrame(data)\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "\n",
    "# Generating 'forecast sales' with the same number of digits as 'actual sales' (ignoring decimals)\n",
    "def forecast_sales(number):\n",
    "    int_part = int(number)  # Convert number to int to ignore decimal part\n",
    "    num_digits = len(str(int_part))  # Get the number of digits in the integer part\n",
    "    \n",
    "    # Generate a random number with the same number of digits by creating\n",
    "    # a string with random digits, then converting it to an integer.\n",
    "    if num_digits == 1:\n",
    "        return np.random.randint(0, 10)\n",
    "    \n",
    "    random_number_str = str(np.random.randint(1, 10))  # Ensure the first digit is not zero\n",
    "    for _ in range(num_digits - 1):\n",
    "        random_number_str += str(np.random.randint(0, 10))\n",
    "    \n",
    "    return int(random_number_str)\n",
    "\n",
    "# Apply the forecast_sales function to each row in 'actual sales'\n",
    "df['forecast sales'] = df['actual sales'].apply(forecast_sales)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c9037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c5ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c0fbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual_sales_cols = [col for col in df.columns if col == 'actual sales']\n",
    "# if len(actual_sales_cols) > 1:\n",
    "#     # Check which 'actual sales' columns have numeric data types\n",
    "#     numeric_cols = [col for col in actual_sales_cols if pd.api.types.is_numeric_dtype(df[col])]\n",
    "    \n",
    "#     if len(numeric_cols) == 0:\n",
    "#         print(\"No numeric 'actual sales' columns to keep.\")\n",
    "#     else:\n",
    "#         # If there are non-numeric 'actual sales' columns, drop them\n",
    "#         if len(numeric_cols) < len(actual_sales_cols):\n",
    "#             non_numeric_cols = list(set(actual_sales_cols) - set(numeric_cols))\n",
    "#             df = df.drop(columns=non_numeric_cols)\n",
    "#             print(f\"Dropped non-numeric 'actual sales' columns: {non_numeric_cols}\")\n",
    "        \n",
    "#         # If all 'actual sales' columns are numeric or after dropping non-numeric ones\n",
    "#         # Keep only the first 'actual sales' column and drop the rest\n",
    "#         df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "#         print(\"Kept only one 'actual sales' column and dropped any duplicates.\")\n",
    "\n",
    "# # The modified DataFrame is now in df with only one 'actual sales' column\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'actual sales' not in df.columns:\n",
    "#     # Column not found, so we generate a new dataframe\n",
    "#     df = generate_custom_data(100)\n",
    "    \n",
    "#     # Remove the original test.csv file\n",
    "#     file_path = 'C:/Users/proshan/OneDrive - SymphonyAI RETAIL CPG/Desktop/Projects/csv dataset generator/Downloads/test.csv'\n",
    "#     os.remove(file_path)\n",
    "    \n",
    "#     # Save the newly generated dataframe as test.csv in the same location\n",
    "#     df.to_csv(file_path, index=False)  # index=False to avoid saving the index column\n",
    "    \n",
    "#     print(\"Original file removed and new data saved as test.csv.\")\n",
    "# else:\n",
    "#     print(\"Column 'actual sales' exists in the dataframe.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
